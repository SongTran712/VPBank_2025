import os
from dotenv import load_dotenv
import boto3
from botocore.config import Config as BotocoreConfig
from strands.models import BedrockModel
from strands import Agent
from gnews import GNews
import json
from upload import read_json_from_s3, upload_text_to_s3, upload_json_to_s3
from crawl import fetch_company_info, fetch_company_person, get_gg_search, get_gg_news, crawl_news

load_dotenv()
AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY")
AWS_SECRET_KEY = os.getenv("AWS_SECRET_KEY")
OPENAI_SECRET_KEY = os.getenv("OPENAI_API_KEY")

google_news = GNews(
            language='vi',
            country='VN',
            max_results=5,
            period='1y',
        )

boto_config = BotocoreConfig(
            retries={"max_attempts": 3, "mode": "standard"},
            connect_timeout=5,
            read_timeout=60
        )
session = boto3.Session(
            aws_access_key_id=AWS_ACCESS_KEY,
            aws_secret_access_key=AWS_SECRET_KEY,
            region_name = "ap-southeast-1"
        )

model = BedrockModel(
            model_id="arn:aws:bedrock:ap-southeast-1:389903776084:inference-profile/apac.amazon.nova-pro-v1:0",
            boto_session=session,
            temperature=0.3,
            top_p=0.8,
            # stop_sequences=["###", "END"],
            # boto_client_config=self.boto_config,
        )

structure_model = BedrockModel(
            model_id="arn:aws:bedrock:ap-southeast-1:389903776084:inference-profile/apac.anthropic.claude-sonnet-4-20250514-v1:0",
            boto_session=session,
            temperature=0.3,
            top_p=0.8,
            # stop_sequences=["###", "END"],
            # boto_client_config=self.boto_config,
        )


def get_risk_data(company_description: str) -> str:
    
    system_prompt = """
You are an intelligent personal assistant, specialized in deep searching, collecting, validating, and analyzing information about companies in Vietnam across various industries.

You have access to the following tools:

    get_gg_news: Search for recent and relevant news articles about a company using Google News.

    get_gg_search: Search for general web information using Google Search (e.g., official websites, financial data, business directories, government sites). Deep dive to research about same topic in 5-10 times and there is no result just return no information

    crawl_news: Extract and retrieve the full content of news articles given their URLs.
    
    Language Requirement:
All outputs must be written in Vietnamese, regardless of the source language of the articles or documents.

Information Validation:

    Prioritize official, reputable, or multi-source-verified information.

    Flag any suspicious, unverified, or biased content, and clearly indicate uncertainty if needed.

Depth over Speed:
Your priority is accuracy and depth of insight, not speed. Only respond when enough quality information is collected and verified.
"""

    risk_agent = Agent(
            tools=[get_gg_search, crawl_news, get_gg_news],
            model= model,
            system_prompt=system_prompt,
        )
    results = risk_agent(company_description)
    output = results.message.get('content', [])[0].get('text', '')
    return output




def generate_company_report(json1: dict, json2: dict) -> str:
    text = []

    # Company Info
    text.append("ğŸ¢ THÃ”NG TIN DOANH NGHIá»†P")
    text.append(f"- TÃªn cÃ´ng ty: {json1['TÃªn cÃ´ng ty']}")
    text.append(f"- LÄ©nh vá»±c hoáº¡t Ä‘á»™ng: {json1['LÄ©nh vá»±c hoáº¡t Ä‘á»™ng']}")
    text.append("- Sáº£n pháº©m chá»§ Ä‘áº¡o:")
    for line in json1['Sáº£n pháº©m chá»§ Ä‘áº¡o'].split('\n'):
        text.append(f"  {line}")
    text.append(f"- CÃ´ng ty máº¹ / sá»Ÿ há»¯u: {json1['CÃ´ng ty máº¹, cÃ´ng ty sá»Ÿ há»¯u']}")

    text.append("\nğŸ“Š PHÃ‚N TÃCH DOANH NGHIá»†P")

    # Good Points
    text.append("\nâœ… Äiá»ƒm tá»‘t:")
    for line in json2['Äiá»ƒm tá»‘t'].split('\n'):
        text.append(f"  {line}")

    # Weaknesses
    text.append("\nâš ï¸ Äiá»ƒm yáº¿u:")
    for line in json2['Äiá»ƒm yáº¿u'].split('\n'):
        text.append(f"  {line}")

    # Risks
    text.append("\nğŸš¨ Rá»§i ro tiá»m áº©n:")
    for line in json2['Rá»§i ro tiá»m áº©n'].split('\n'):
        text.append(f"  {line}")

    # Summary
    text.append("\nğŸ§¾ Tá»”NG QUAN:")
    for line in json2['Tá»•ng quan'].split('\n'):
        text.append(f"  {line}")

    return '\n'.join(text)

def risk_report_agent( risk_problem = 'TÃ i chÃ­nh'):

    try:

        try:
            risk_data = get_risk_data(risk_problem)
        except Exception as e:
            return f"Error analyzing risk data: {e}"
        return risk_data

    except Exception as e:
        return f"Unhandled error in risk_report_agent: {e}"
    

def setup_risk_topic(bucket='testworkflow123', prefixs= ['info_crawl_agent/companyInfo.json', 'fin_agent/fin_data.json']):
    try:
        company_data_raw = read_json_from_s3(bucket, prefixs[0])
        if not company_data_raw:
            raise ValueError("Company data not found.")
        company_data = json.loads(company_data_raw)
    except Exception as e:
        return f"Error reading or parsing company info: {e}"

    # Step 2: Read financial data
    try:
        fin_data_raw = read_json_from_s3(bucket, prefixs[1])
        if not fin_data_raw:
            raise ValueError("Financial data not found.")
        fin_data = json.loads(fin_data_raw)
    except Exception as e:
        return f"Error reading or parsing financial info: {e}"
    ten_cty = company_data.get('TÃªn cÃ´ng ty')
    ban_ld = company_data.get('Ban lÃ£nh Ä‘áº¡o')
    cty_me_con = company_data.get('CÃ´ng ty máº¹, cÃ´ng ty sá»Ÿ há»¯u')
    sanpham = company_data.get("Sáº£n pháº©m chá»§ Ä‘áº¡o")
    thitruong = company_data.get('LÄ©nh vá»±c hoáº¡t Ä‘á»™ng')
    lsu = risk_report_agent(f"""
Your mission is to findout about history of {ten_cty}, you can reference following {cty_me_con} for more details but priority still be {ten_cty}
    """)
    
    sp_out = risk_report_agent(f"""
PhÃ¢n tÃ­ch vá» sáº£n pháº©m chá»§ Ä‘áº¡o {sanpham} cá»§a cÃ´ng ty {ten_cty}, sá»± ná»•i trá»™i vÃ  háº¡n cháº¿ cá»§a sáº£n pháº©m so vá»›i cÃ¡c sáº£n pháº©m khÃ¡c trong thá»‹ trÆ°á»ng {thitruong}
                                """)
    mohinh_quanly = risk_report_agent(f""""
PhÃ¢n tÃ­ch cÃ¡c thÃ nh viÃªn {ban_ld} trong cÃ´ng ty {ten_cty}. ÄÆ°a ra mÃ´ hÃ¬nh quáº£n lÃ½ vÃ  tÃ¬m hiá»ƒu sÆ¡ yáº¿u lÃ½ lá»‹ch vÃ  Ä‘Æ°a ra nhá»¯ng Ä‘Ã³ng gÃ³p hay nhá»¯ng tá»•n tháº¥t há» gÃ¢y ra vá»›i xÃ£ há»™i Ä‘áº·c biá»‡t táº¡i Viá»‡t Nam 
                                          """)
    taichinh = risk_report_agent(f"""
PhÃ¢n tÃ­ch tÃ¬nh hÃ¬nh tÃ i chÃ­nh cá»§a cÃ´ng ty {ten_cty} dá»±a trÃªn {fin_data} vÃ  tÃ¬m hiá»ƒu thÃªm vá» tÃ¬nh hÃ¬nh ná»£ vá»›i cÃ¡c ngÃ¢n hÃ ng bÃªn ngoÃ i hay vá» dÃ²ng tiá»n cá»§a cÃ´ng ty 
                                 """)
    ruiro = risk_report_agent(f"""
PhÃ¢n tÃ­ch táº¥t cÃ¡c rá»§i ro khi cho {ten_cty} vay mÆ°á»£n. Bao gá»“m: 
Rá»§i ro chiáº¿n lÆ°á»£c (rá»§i ro vá» táº§m nhÃ¬n cÃ´ng ty, rá»§i ro vá» cáº¡nh tranh, rá»§i ro kinh doanh )
Rá»§i ro hoáº¡t Ä‘á»™ng (rá»§i ro cÃ´ng bá»‘ thÃ´ng tin, rá»§i ro vá» nguá»“n nhÃ¢n lá»±c, rá»§i ro báº£o máº­t)
Rá»§i ro luáº­t Ä‘á»‹nh (nhá»¯ng rá»§i ro liÃªn quan Ä‘áº¿n chÃ­nh sÃ¡ch, phÃ¡p luáº­t).

PhÃ¢n tÃ­ch giáº£i phÃ¡p kháº£ thi chÃ³ cÃ¡c rá»§i ro Ä‘Ã³
                                 """)
    
    final = f"""
Lá»‹ch sá»­ hÃ¬nh thÃ nh: {lsu}
Sáº£n pháº£m chá»§ Ä‘áº¡o: {sp_out}
MÃ´ hÃ¬nh quáº£n lÃ½: {mohinh_quanly}
TÃ i chÃ­nh rá»§i ro: {taichinh}
Rá»§i ro khÃ¡c: {ruiro}
    """
    upload_text_to_s3(bucket, 'content/risk_analyst/lichsu.txt', lsu)
    upload_text_to_s3(bucket, 'content/risk_analyst/spchuyeu.txt', sp_out)
    upload_text_to_s3( bucket, 'content/risk_analyst/mohinhquanly.txt', mohinh_quanly)
    upload_text_to_s3( bucket,  'content/risk_analyst/ruirotaichinh.txt', taichinh)
    upload_text_to_s3(bucket, 'content/risk_analyst/ruiro.txt', ruiro)

    return final



if __name__ == "__main__":
    output = setup_risk_topic()
    print(output)